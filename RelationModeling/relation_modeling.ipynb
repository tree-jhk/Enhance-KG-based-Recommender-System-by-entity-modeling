{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../../TextModel/\")\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import KernelPCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from surprise import SVD, NMF, Dataset, Reader\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation 1: is_similar_storyline\n",
    "- storyline에 대한 text embedding을 구한다.\n",
    "- text embedding간의 cosine similarity를 구한다.\n",
    "- 유사도가 threshold 이상이 되는 text pair만을 '유사하다'고 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"../../Data/TMDB/tmdb_5000_movies.csv\")\n",
    "movies = movies.dropna(subset=['overview'])\n",
    "movies = movies.reset_index()\n",
    "emb = np.load(\"./text_embedding/text_embedding.npy\")\n",
    "\n",
    "credits = pd.read_csv(\"../../Data/TMDB/tmdb_5000_credits.csv\")\n",
    "credits.rename(columns={'movie_id':'id'}, inplace=True)\n",
    "tmp = pd.DataFrame(movies[['id', 'original_title']])\n",
    "credits = pd.merge(left=credits, right=tmp, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 각 row 간의 cosine similarity 계산\n",
    "cos_sim = cosine_similarity(emb)\n",
    "result_dict = defaultdict(list)\n",
    "threshold = 0.85\n",
    "\n",
    "for i in range(0, len(cos_sim) - 1):\n",
    "    for j in range(i + 1, len(cos_sim)):\n",
    "        if cos_sim[i][j] >= threshold:\n",
    "            result_dict[i].append((j, cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "for key, value in result_dict.items():\n",
    "    movie_idx = key\n",
    "    movie_title = movies.iloc[movie_idx]['original_title']\n",
    "    movie_title_ = movies.iloc[movie_idx]['title']\n",
    "    for sim_movie_idx, sim in value:\n",
    "        sim_movie_title = movies.iloc[sim_movie_idx]['original_title']\n",
    "        result_list.append([movie_title, sim_movie_title, sim, movie_title_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sim_df = pd.DataFrame(result_list, columns=['original_title', 'similar_movie_title', 'cosine_similarity', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88069"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2753"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>similar_movie_title</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Penguins of Madagascar</td>\n",
       "      <td>0.861668</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             original_title     similar_movie_title  \\\n",
       "0  Pirates of the Caribbean: At World's End  Penguins of Madagascar   \n",
       "\n",
       "   cosine_similarity                                     title  \n",
       "0           0.861668  Pirates of the Caribbean: At World's End  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sim_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation 2: cluster_group_of\n",
    "- storyline에 대한 text embedding을 구한다.\n",
    "- text embedding들을 t-sne로 차원 축소 이후\n",
    "- 차원 축소된 vector들을 k-means 알고리즘으로 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3)\n",
    "tsne_embeddings = tsne.fit_transform(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "\n",
    "kmeans = KMeans(n_clusters=n, random_state=0)\n",
    "kmeans.fit(tsne_embeddings)\n",
    "clusters = kmeans.predict(tsne_embeddings)\n",
    "\n",
    "print(f\"number of generarated clusters: {len(set(clusters))}\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1], tsne_embeddings[:, 2], c=clusters, cmap='tab20')\n",
    "ax.set_title(f'n_clusters={n} Clustering Result')\n",
    "fig.savefig(f'./{n}.png')\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter(clusters)\n",
    "val = cnt.values()\n",
    "print(f'n_clusters={n} Clustering Result:')\n",
    "print(dict(sorted(cnt.items(), key=lambda x:(x[1], x[0]))))\n",
    "max_ = max(val)\n",
    "min_ = min(val)\n",
    "avg_ = sum(val) // len(val)\n",
    "ratio = round(abs(max_ - min_) / avg_, 3)\n",
    "s_score = silhouette_score(tsne_embeddings, clusters)\n",
    "print(f\"{max_=}   {min_=}   {avg_=}   {ratio=}   {s_score=}\")\n",
    "print(\"================================\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.DataFrame(clusters, columns=['cluster_id'])\n",
    "cluster_data = pd.concat([movies[['original_title', 'overview', 'title']], clusters_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = pd.read_csv(\"./cluster_result/cluster_data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation 3: is_director\n",
    "- tmdb_credits에서 json parsing을 통해 'Director' 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "movietitle_director_dict = defaultdict(list)\n",
    "movietitle_director_dict_ = defaultdict(list)\n",
    "\n",
    "for row in credits.iterrows():\n",
    "    row_data = row[1]\n",
    "    movie_title = row_data.original_title\n",
    "    movie_title_ = row_data.title\n",
    "    json_parsing = json.loads(row_data.crew)\n",
    "    tmp = []\n",
    "    for crew_data in json_parsing:\n",
    "        if crew_data['job'] == 'Director':\n",
    "            tmp.append(crew_data['name'])\n",
    "    movietitle_director_dict[movie_title] = tmp\n",
    "    movietitle_director_dict_[movie_title_] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movietitle_director_df = pd.DataFrame([(title, director, title_) for (title, directors), (title_, directors_) in zip(movietitle_director_dict.items(), movietitle_director_dict_.items()) for director in directors], columns=['original_title', 'director_name', 'title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 제목 전처리\n",
    "- 영화 제목을 전처리한다.\n",
    "- 이를 통해 MovieLens 데이터와 merge될 수 있도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmdb_preprocess_title(df:pd.DataFrame):\n",
    "    if 'original_title' in df.columns:\n",
    "        df.title = df.title.apply(lambda x: x.lower())\n",
    "        df.original_title = df.original_title.apply(lambda x: x.lower())\n",
    "        \n",
    "        df.loc[df['title'] =='america is still the place', 'original_title'] = 'america is still the place'\n",
    "        df.drop(columns='title', inplace=True)\n",
    "        df.rename(columns={'original_title':'title'}, inplace=True)\n",
    "\n",
    "        # tmdb에서 title 같은데, 출시일자가 달라서 다르고 줄거리는 같은 영화는 중복 제거\n",
    "        df.drop_duplicates(['title'], keep='first', inplace=True)\n",
    "        \n",
    "        if 'similar_movie_title' in df.columns:\n",
    "            df['similar_movie_title'] = df['similar_movie_title'].apply(lambda x: x.lower())\n",
    "            \n",
    "            df.loc[df['similar_movie_title'] =='america is still the place', 'similar_movie_title'] = 'america is still the place'\n",
    "            # tmdb에서 title 같은데, 출시일자가 달라서 다르고 줄거리는 같은 영화는 중복 제거\n",
    "            df.drop_duplicates(['similar_movie_title'], keep='first', inplace=True)\n",
    "            df.rename(columns={'similar_movie_title':'similar_title'}, inplace=True)\n",
    "    elif 'cosine_similarity' in df.columns:\n",
    "        df['movie_title'] = df['movie_title'].apply(lambda x: x.lower())\n",
    "        \n",
    "        df.loc[df['movie_title'] =='america is still the place', 'movie_title'] = 'america is still the place'\n",
    "        # tmdb에서 title 같은데, 출시일자가 달라서 다르고 줄거리는 같은 영화는 중복 제거\n",
    "        df.drop_duplicates(['movie_title'], keep='first', inplace=True)\n",
    "        df.rename(columns={'movie_title':'title'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sim_df = tmdb_preprocess_title(text_sim_df)\n",
    "cluster_data = tmdb_preprocess_title(cluster_data)\n",
    "movietitle_director_df = tmdb_preprocess_title(movietitle_director_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sim_df.to_csv(\"./preprocess_phase_0/similarity.csv\", index=False)\n",
    "cluster_data.to_csv(\"./preprocess_phase_0/cluster.csv\", index=False)\n",
    "movietitle_director_df.to_csv(\"./preprocess_phase_0/director.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF 기반 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"../../Data/MovieLens/ratings.csv\")\n",
    "# 데이터 불러오기\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "# SVD 모델 학습\n",
    "model = NMF(n_factors=50, n_epochs=30, biased=False)\n",
    "trainset = data.build_full_trainset()\n",
    "model.fit(trainset)\n",
    "\n",
    "# 사용자 임베딩 추출\n",
    "user_id = 1\n",
    "user_embedding = model.pu[user_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation 4: is_similar_user\n",
    "- surprise 라이브러리의 NMF 기반 평점 예측\n",
    "- user embedding 구함\n",
    "- 유사도가 threshold 이상이 되는 user pair만을 '유사하다'고 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb = model.pu\n",
    "\n",
    "# user embedding에 대한 각 row 간의 cosine similarity 계산\n",
    "cos_sim = cosine_similarity(user_emb)\n",
    "result_dict = defaultdict(list)\n",
    "threshold = 0.90\n",
    "\n",
    "for i in range(0, len(cos_sim) - 1):\n",
    "    for j in range(i + 1, len(cos_sim)):\n",
    "        if cos_sim[i][j] >= threshold:\n",
    "            result_dict[i].append((j, cos_sim[i][j]))\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for key, value in result_dict.items():\n",
    "    idx = key\n",
    "    for sim_idx, sim in value:\n",
    "        result_list.append([idx, sim_idx, sim])\n",
    "\n",
    "user_sim_df = pd.DataFrame(result_list, columns=['user_id', 'similar_user_id', 'cosine_similarity'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation 5: is_similar_item\n",
    "- surprise 라이브러리의 NMF 기반 평점 예측\n",
    "- item embedding 구함\n",
    "- 유사도가 threshold 이상이 되는 item pair만을 '유사하다'고 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_emb = model.qi\n",
    "\n",
    "# item embedding에 대한 각 row 간의 cosine similarity 계산\n",
    "cos_sim = cosine_similarity(item_emb)\n",
    "result_dict = defaultdict(list)\n",
    "threshold = 0.90\n",
    "\n",
    "for i in range(0, len(cos_sim) - 1):\n",
    "    for j in range(i + 1, len(cos_sim)):\n",
    "        if cos_sim[i][j] >= threshold:\n",
    "            result_dict[i].append((j, cos_sim[i][j]))\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for key, value in result_dict.items():\n",
    "    idx = key\n",
    "    for sim_idx, sim in value:\n",
    "        result_list.append([idx, sim_idx, sim])\n",
    "\n",
    "item_sim_df = pd.DataFrame(result_list, columns=['item_id', 'similar_item_id', 'cosine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sim_df.to_csv(\"./preprocess_phase_0/user_sim.csv\", index=False)\n",
    "item_sim_df.to_csv(\"./preprocess_phase_0/item_sim.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
